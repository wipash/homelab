---
# yaml-language-server: $schema=https://kubernetes-schemas.pages.dev/postgresql.cnpg.io/cluster_v1.json
apiVersion: postgresql.cnpg.io/v1
kind: Cluster
metadata:
  name: postgres16
spec:
  instances: 2
  imageName: ghcr.io/cloudnative-pg/postgresql:16.3-1
  primaryUpdateStrategy: unsupervised
  storage:
    size: 20Gi
    storageClass: openebs-hostpath
  superuserSecret:
    name: cloudnative-pg-secret
  enableSuperuserAccess: true
  postgresql:
    parameters:
      max_connections: "600"
      max_slot_wal_keep_size: 10GB
      shared_buffers: 512MB
  resources:
    requests:
      cpu: 200m
    limits:
      memory: 2Gi
  monitoring:
    enablePodMonitor: true
    # Ref: https://github.com/cloudnative-pg/cloudnative-pg/issues/2501
    podMonitorMetricRelabelings:
      - { sourceLabels: ["cluster"], targetLabel: cnpg_cluster, action: replace }
      - { regex: cluster, action: labeldrop }
  backup:
    retentionPolicy: 30d
    barmanObjectStore: &barmanObjectStore
      data:
        compression: bzip2
      wal:
        compression: bzip2
        maxParallel: 8
      destinationPath: s3://cnpgbackup/
      endpointURL: https://s3.us-west-001.backblazeb2.com
      # Note: serverName version needs to be incremented
      # when recovering from an existing cnpg cluster
      serverName: &currentCluster postgres16-v2
      s3Credentials:
        accessKeyId:
          name: cloudnative-pg-secret
          key: aws-access-key-id
        secretAccessKey:
          name: cloudnative-pg-secret
          key: aws-secret-access-key
  # Note: previousCluster needs to be set to the name of the previous
  # cluster when recovering from an existing cnpg cluster
  bootstrap:
    recovery:
      source: &previousCluster postgres16-v1
  # Note: externalClusters is needed when recovering from an existing cnpg cluster
  externalClusters:
    - name: *previousCluster
      barmanObjectStore:
        <<: *barmanObjectStore
        serverName: *previousCluster
