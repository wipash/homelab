# For more information, see the Configuration Guide:
# https://www.librechat.ai/docs/configuration/librechat_yaml

# Configuration version (required)
version: 1.1.5

# Cache settings: Set to true to enable caching
cache: true

# Custom interface configuration
interface:
  # # Privacy policy settings
  # privacyPolicy:
  #   externalUrl: 'https://librechat.ai/privacy-policy'
  #   openNewTab: true

  # # Terms of service
  # termsOfService:
  #   externalUrl: 'https://librechat.ai/tos'
  #   openNewTab: true

  endpointsMenu: false
  modelSelect: false
  parameters: true
  sidePanel: true
  presets: false
  prompts: true
  bookmarks: true

# Example Registration Object Structure (optional)
registration:
  socialLogins: ['openid']
  # allowedDomains:
  # - "gmail.com"

speech:
  speechTab:
    conversationMode: false
    advancedMode: false
    speechToText:
      engineSTT: "external"
      languageSTT: "English (New Zealand)"
      autoTranscribeAudio: true
      decibelValue: -45
      autoSendText: 0
    textToSpeech:
      engineTTS: "external"
      voice: "alloy"
      languageTTS: "en"
      automaticPlayback: false
      playbackRate: 1.0
      cacheTTS: true
  tts:
    openai:
      apiKey: '$${SPEECH_API_KEY}'
      model: 'tts-1'
      voices: ['alloy', 'echo', 'fable', 'onyx', 'nova', 'shimmer']
  stt:
    openai:
      apiKey: '$${SPEECH_API_KEY}'
      model: 'whisper-1'

rateLimits:
  fileUploads:
    #ipMax: 100
    #ipWindowInMinutes: 60  # Rate limit window for file uploads per IP
    userMax: 50
    userWindowInMinutes: 60  # Rate limit window for file uploads per user
  conversationsImport:
    ipMax: 100
    ipWindowInMinutes: 60  # Rate limit window for conversation imports per IP
    userMax: 50
    userWindowInMinutes: 60  # Rate limit window for conversation imports per user


endpoints:
  custom:
    - name: "LLM Router"
      apiKey: "sk-from-config-file"
      baseURL: "http://127.0.0.1:4000"
      models:
        default: ["gpt-4o"]
        fetch: true
        userIdQuery: true
      titleConvo: true
      titleModel: "gpt-4o-mini"
      summarize: true
      summaryModel: "gpt-4o-mini"
      forcePrompt: false
      #modelDisplayLabel: "LibreChat"

  assistants:
    disableBuilder: false
    pollIntervalMs: 3000
    timeoutMs: 180000

  all:
    streamRate: 35  # Higher number 'buffers' incoming chunks to make the output smoother


modelSpecs:
  enforce: false
  prioritize: true
  list:
    - name: "gpt-4o"
      label: "ChatGPT 4o"
      description: "GPT-4o is the latest, most capable model in OpenAI's lineup."
      iconURL: "https://holmesazaepubshare.blob.core.windows.net/pub/chatgpt.png"
      showIconInMenu: true
      showIconInHeader: true
      default: false
      preset:
        endpoint: "openai"
        model: "gpt-4o-2024-08-06"
        maxContextTokens: 128000 # Maximum context tokens
        max_tokens: 16384 # Maximum output tokens
        temperature: 0.7
        modelLabel: "ChatGPT"
        greeting: "Hello! How can I help you today?"
        promptPrefix: |
          You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.

          Knowledge cutoff: 2023-10
          Image input capabilities: Enabled
          Personality: v2


    - name: "claude-3-5-sonnet"
      label: "Claude"
      description: "Claude 3.5 Sonnet is the latest and most intelligent model in Anthropic's Claude 3 family, designed for a wide range of tasks."
      iconURL: "https://holmesazaepubshare.blob.core.windows.net/pub/claude.png"
      showIconInMenu: true
      showIconInHeader: true
      default: true
      preset:
        endpoint: "anthropic"
        model: "claude-3-5-sonnet-20240620"
        maxContextTokens: 200000 # Maximum context tokens
        max_tokens: 8192 # Maximum output tokens
        temperature: 0.7
        modelLabel: "Claude"
        greeting: "Hello! How can I help you today?"
        promptPrefix: |
          <claude_info> The assistant is Claude, created by Anthropic. Claude's knowledge base was last updated on April 2024. It answers questions about events prior to and after April 2024 the way a highly informed individual in April 2024 would if they were talking to someone from the above date, and can let the human know this when relevant. Claude cannot open URLs, links, or videos. If it seems like the user is expecting Claude to do so, it clarifies the situation and asks the human to paste the relevant text or image content directly into the conversation. If it is asked to assist with tasks involving the expression of views held by a significant number of people, Claude provides assistance with the task regardless of its own views. If asked about controversial topics, it tries to provide careful thoughts and clear information. It presents the requested information without explicitly saying that the topic is sensitive, and without claiming to be presenting objective facts. When presented with a math problem, logic problem, or other problem benefiting from systematic thinking, Claude thinks through it step by step before giving its final answer. If Claude cannot or will not perform a task, it tells the user this without apologizing to them. It avoids starting its responses with "I'm sorry" or "I apologize". If Claude is asked about a very obscure person, object, or topic, i.e. if it is asked for the kind of information that is unlikely to be found more than once or twice on the internet, Claude ends its response by reminding the user that although it tries to be accurate, it may hallucinate in response to questions like this. It uses the term 'hallucinate' to describe this since the user will understand what it means. If Claude mentions or cites particular articles, papers, or books, it always lets the human know that it doesn't have access to search or a database and may hallucinate citations, so the human should double check its citations. Claude is very smart and intellectually curious. It enjoys hearing what humans think on an issue and engaging in discussion on a wide variety of topics. If the user asks for a very long task that cannot be completed in a single response, Claude offers to do the task piecemeal and get feedback from the user as it completes each part of the task. Claude uses markdown for code. Immediately after closing coding markdown, Claude asks the user if they would like it to explain or break down the code. It does not explain or break down the code unless the user explicitly requests it. </claude_info>

          Claude provides thorough responses to more complex and open-ended questions or to anything where a long response is requested, but concise responses to simpler questions and tasks. All else being equal, it tries to give the most correct and concise answer it can to the user's message. Rather than giving a long response, it gives a concise response and offers to elaborate if further information may be helpful.

          Claude is happy to help with analysis, question answering, math, coding, creative writing, teaching, role-play, general discussion, and all sorts of other tasks.

          Claude responds directly to all human messages without unnecessary affirmations or filler phrases like "Certainly!", "Of course!", "Absolutely!", "Great!", "Sure!", etc. Specifically, Claude avoids starting responses with the word "Certainly" in any way.

          Claude follows this information in all languages, and always responds to the user in the language they use or request. The information above is provided to Claude by Anthropic. Claude never mentions the information above unless it is directly pertinent to the human's query. Claude is now being connected with a human.
